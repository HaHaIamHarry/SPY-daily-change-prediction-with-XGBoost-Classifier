{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SPY daily change prediction with XGBoost Classifier\n",
        "by Harry Ho"
      ],
      "metadata": {
        "id": "XIRKty-EUlkb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project will first use logistic regression to find out which predictors works in predicting SPY(SPDR S&P 500 ETF Trust) weekly change, then use XGBoost Classifier to find out whether SPY will go up or go down with predictors that are effective in logistic regression."
      ],
      "metadata": {
        "id": "Ap1A19EAUx1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing package"
      ],
      "metadata": {
        "id": "bBVTFOcbVOEb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1b0hHMyUeOe",
        "outputId": "8807060d-f85b-45ec-e6a9-c763ceba5731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.31)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.23.5)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.3)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2023.3.post1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.3.8)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.11.2)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2023.7.22)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.23.5)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.11.3)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.5.3)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (0.5.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (23.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->statsmodels) (2023.3.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install statsmodels\n",
        "!pip install xgboost\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import statsmodels.api as sm\n",
        "from datetime import datetime, timedelta\n",
        "from pytz import timezone, utc\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download SPY history price from Yahoo Finance"
      ],
      "metadata": {
        "id": "RzCByQ4eVkUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Date setup\n",
        "date = datetime.now(tz=utc)\n",
        "today = date.astimezone(timezone('US/Pacific'))\n",
        "today = today+ timedelta(days=1)\n",
        "today_date = today.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# Data Retrieval\n",
        "start_date = \"2003-01-01\"\n",
        "end_date = today_date\n",
        "ticker = \"SPY\"\n",
        "yfdata = yf.download(ticker, start_date, end_date)\n",
        "SPY_df = yfdata[[\"Close\"]]\n",
        "SPY_df = SPY_df.reset_index()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmI5c4eYWCXQ",
        "outputId": "cd8ec319-5b0a-4a27-8090-40f186c7963e"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up predictors\n"
      ],
      "metadata": {
        "id": "HNsb5aPhWLOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['1W_diff','3W_diff','10W_diff','1diff', '2diff', '3diff', '4diff', 'dir', '2dir' , '3dir' , '4dir' ,'signal',\"MACD10\",\"MACD20\",\"MACD30\",\"SO10\",\"SO20\",\"SO30\"]\n",
        "for i in range(1, 6):\n",
        "    SPY_df[f'{i}diff'] = -(SPY_df['Close'].shift(i) - SPY_df['Close']) / SPY_df['Close'].shift(i)\n",
        "SPY_df['dir'] = np.where(SPY_df['1diff'] >= 0, 1, 0)\n",
        "SPY_df['2dir'] = np.where(SPY_df['1diff'].shift(1) >= 0, 1, 0)\n",
        "SPY_df['3dir'] = np.where(SPY_df['1diff'].shift(2) >= 0, 1, 0)\n",
        "SPY_df['4dir'] = np.where(SPY_df['1diff'].shift(3) >= 0, 1, 0)\n",
        "for i in range(2, 5):\n",
        "    condition = np.prod([SPY_df['dir'].shift(j) == 0 for j in range(i)], axis=0) & (SPY_df['dir'] == 0)\n",
        "    SPY_df[f'{i}down'] = np.where(condition, 1, 0)\n",
        "for i in range(2, 5):\n",
        "    condition = np.prod([SPY_df['dir'].shift(j) == 1 for j in range(i)], axis=0) & (SPY_df['dir'] == 1)\n",
        "    SPY_df[f'{i}up'] = np.where(condition, 1, 0)\n",
        "SPY_df['1W_diff'] = -(SPY_df['Close'].shift(5) - SPY_df['Close']) / SPY_df['Close'].shift(5)\n",
        "SPY_df['3W_diff'] = -(SPY_df['Close'].shift(15) - SPY_df['Close']) / SPY_df['Close'].shift(15)\n",
        "SPY_df['10W_diff'] = -(SPY_df['Close'].shift(50) - SPY_df['Close']) / SPY_df['Close'].shift(50)\n",
        "SPY_df['bottom'] = np.nan\n",
        "SPY_df['top'] = np.nan\n",
        "SPY_df['signal'] = np.nan\n",
        "SPY_df['bottom'] = np.where((SPY_df['1diff'].shift(1) < 0) & (SPY_df['1diff'] > 0), SPY_df['Close'].shift(1), SPY_df['bottom'].shift(1))\n",
        "SPY_df['bottom'].fillna(method='ffill', inplace=True)\n",
        "SPY_df['top'] = np.where((SPY_df['1diff'].shift(1) > 0) & (SPY_df['1diff'] < 0), SPY_df['Close'].shift(1), SPY_df['top'].shift(1))\n",
        "SPY_df['top'].fillna(method='ffill', inplace=True)\n",
        "SPY_df['signal'] = np.where(SPY_df['Close'] >= SPY_df['top'], 1, np.where(SPY_df['Close'] <= SPY_df['bottom'], 0, SPY_df['signal'].shift(1)))\n",
        "SPY_df['signal'].fillna(method='ffill', inplace=True)\n",
        "SPY_df['Mean10'] = SPY_df['Close'].rolling(window=10).mean()\n",
        "SPY_df['MACD10'] = (SPY_df['Close'] - SPY_df['Mean10']) / SPY_df['Mean10']\n",
        "SPY_df['Mean20'] = SPY_df['Close'].rolling(window=20).mean()\n",
        "SPY_df['MACD20'] = (SPY_df['Close'] - SPY_df['Mean20']) / SPY_df['Mean20']\n",
        "SPY_df['Mean30'] = SPY_df['Close'].rolling(window=30).mean()\n",
        "SPY_df['MACD30'] = (SPY_df['Close'] - SPY_df['Mean30']) / SPY_df['Mean30']\n",
        "SPY_df['Max10'] = SPY_df['Close'].rolling(window=10).max()\n",
        "SPY_df['Min10'] = SPY_df['Close'].rolling(window=10).min()\n",
        "SPY_df['SO10'] = (SPY_df['Close'] - SPY_df['Min10']) / (SPY_df['Max10']-SPY_df['Min10'])\n",
        "SPY_df['Max20'] = SPY_df['Close'].rolling(window=20).max()\n",
        "SPY_df['Min20'] = SPY_df['Close'].rolling(window=20).min()\n",
        "SPY_df['SO20'] = (SPY_df['Close'] - SPY_df['Min20']) / (SPY_df['Max20']-SPY_df['Min20'])\n",
        "SPY_df['Max30'] = SPY_df['Close'].rolling(window=30).max()\n",
        "SPY_df['Min30'] = SPY_df['Close'].rolling(window=30).min()\n",
        "SPY_df['SO30'] = (SPY_df['Close'] - SPY_df['Min30']) / (SPY_df['Max30']-SPY_df['Min30'])\n",
        "SPY_df['fut_dir'] = SPY_df['dir'].shift(-1)"
      ],
      "metadata": {
        "id": "EFbwSF9RXB1e"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spliting data into training and testing dataset"
      ],
      "metadata": {
        "id": "Xdgg4AaYXFwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Splitting Data\n",
        "X_train = SPY_df.iloc[100:4000][features]\n",
        "y_train = SPY_df.iloc[100:4000]['fut_dir']\n",
        "X_test = SPY_df.iloc[4001:5100][features]\n",
        "y_test = SPY_df.iloc[4001:5100]['fut_dir']\n"
      ],
      "metadata": {
        "id": "8zL27z_4XMYc"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use logistic regression to find out which predictor is useful (backward elimination with AIC)"
      ],
      "metadata": {
        "id": "eeGljRoLXNQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Backward Elimination using AIC\n",
        "X_train_with_const = sm.add_constant(X_train)\n",
        "while (len(features) > 0):\n",
        "    features_with_constant = ['const'] + features\n",
        "    model = sm.Logit(y_train, X_train_with_const[features_with_constant]).fit(disp=0)\n",
        "    max_aic = float(\"inf\")\n",
        "    worst_feature = None\n",
        "    for feature in features:\n",
        "        temp_features = features[:]\n",
        "        temp_features.remove(feature)\n",
        "        temp_features_with_const = ['const'] + temp_features\n",
        "        temp_model = sm.Logit(y_train, X_train_with_const[temp_features_with_const]).fit(disp=0)\n",
        "        if temp_model.aic < max_aic:\n",
        "            max_aic = temp_model.aic\n",
        "            worst_feature = feature\n",
        "    if max_aic < model.aic:\n",
        "        features.remove(worst_feature)\n",
        "    else:\n",
        "        break"
      ],
      "metadata": {
        "id": "VhjV-Ry1XX5Z"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the model with XGBoost Classifer"
      ],
      "metadata": {
        "id": "W4lUcu-EXXYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Refitting the model using XGBoost\n",
        "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators=10, max_depth = 4)\n",
        "xgb_model.fit(X_train[features], y_train)\n",
        "y_pred = xgb_model.predict(X_test[features])\n"
      ],
      "metadata": {
        "id": "LMFSf_5dXhOp"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result of training"
      ],
      "metadata": {
        "id": "Hcta-gNaXhsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training evaluation\n",
        "y_train_pred = xgb_model.predict(X_train[features])\n",
        "accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(f\"XGBoost Model Accuracy of training dataset after backward elimination (AIC): {accuracy*100:.2f}%\")\n",
        "print(\"Selected features:\", features)\n",
        "print(\"Confusion Matrix of training dataset:\")\n",
        "print(confusion_matrix(y_train, y_train_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MncekWoGXpFW",
        "outputId": "d954ec7a-5ac2-4355-8ccc-c07f9ca5c6ee"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Model Accuracy of training dataset after backward elimination (AIC): 60.87%\n",
            "Selected features: ['3W_diff', '1diff', '3diff', '3dir', '4dir', 'SO10']\n",
            "Confusion Matrix of training dataset:\n",
            "[[ 422 1333]\n",
            " [ 193 1952]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of applying the model to the testing dataset"
      ],
      "metadata": {
        "id": "SZ3BFBpQXqHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"XGBoost Model Accuracy after backward elimination (AIC): {accuracy*100:.2f}%\")\n",
        "print(\"Selected features:\", features)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW85t4gnVcVE",
        "outputId": "50d83feb-c2a1-43d2-d35b-12596073f2fe"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Model Accuracy after backward elimination (AIC): 54.96%\n",
            "Selected features: ['3W_diff', '1diff', '3diff', '3dir', '4dir', 'SO10']\n",
            "Confusion Matrix:\n",
            "[[126 376]\n",
            " [119 478]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model archieved a Precision (Positive predictive value) of : 478/(376+478) = 55.97%"
      ],
      "metadata": {
        "id": "93ytxOhvbpVF"
      }
    }
  ]
}